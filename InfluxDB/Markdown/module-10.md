# Module 10: Capstone Project & Best Practices

**Duration:** 30 minutes  
**Level:** Advanced

---

## Table of Contents

1. [Introduction](#introduction)
2. [Capstone Project Overview](#capstone-project-overview)
3. [Phase 1: Architecture Design](#phase-1-architecture-design)
4. [Phase 2: Data Collection](#phase-2-data-collection)
5. [Phase 3: Storage & Retention](#phase-3-storage-retention)
6. [Phase 4: Querying & Analytics](#phase-4-querying-analytics)
7. [Phase 5: Visualization](#phase-5-visualization)
8. [Phase 6: Alerting](#phase-6-alerting)
9. [Performance Validation & Tuning](#performance-validation-tuning)
10. [Production Best Practices](#production-best-practices)
11. [Future Roadmap](#future-roadmap)
12. [Final Assessment](#final-assessment)

---

## Introduction

Congratulations on reaching the final module! This capstone project brings together everything you've learned throughout the course. You'll build a complete, production-ready monitoring system that demonstrates best practices and real-world implementation patterns.

### Module Objectives

- Design and implement an end-to-end monitoring solution
- Apply performance optimization techniques
- Implement production-grade best practices
- Understand InfluxDB's future direction
- Validate your comprehensive understanding of InfluxDB

---

## Capstone Project Overview

### Project: Enterprise System Monitoring Platform

**Objective:** Build a comprehensive monitoring platform that collects, stores, analyzes, visualizes, and alerts on system metrics across multiple servers.

### Project Requirements

1. **Data Collection**

   - Monitor 5+ virtual/simulated servers
   - Collect CPU, memory, disk, and network metrics
   - Ingest rate: 100+ points per second
   - Handle batch writes efficiently

2. **Storage**

   - Implement multi-tier retention policies
   - Hot data: 7 days (high precision)
   - Warm data: 90 days (hourly aggregates)
   - Cold data: 1 year (daily summaries)

3. **Querying**

   - Real-time queries for current status
   - Historical analysis queries
   - Aggregation and downsampling
   - Multi-server comparisons

4. **Visualization**

   - Real-time dashboard
   - Historical trends
   - Comparison views
   - Custom annotations

5. **Alerting**
   - Threshold-based alerts
   - Anomaly detection
   - Multi-channel notifications
   - Alert suppression logic

### Success Criteria

âœ… All components functional and integrated  
âœ… Handles target load without performance degradation  
âœ… Meets retention policy requirements  
âœ… Alerts trigger accurately  
âœ… Dashboards update in real-time  
âœ… System is maintainable and documented

---

## Phase 1: Architecture Design

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Data Sources Layer                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Server 1 â”‚  â”‚ Server 2 â”‚  â”‚ Server N â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Collection Agent       â”‚
        â”‚    (Python/Telegraf)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       InfluxDB 2.x        â”‚
        â”‚                           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Raw Metrics (7d)    â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚             â”‚             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Aggregated (90d)    â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚             â”‚             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Historical (1y)     â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚  Tasks    â”‚ â”‚ Grafana â”‚ â”‚  Alerts   â”‚
  â”‚(Downsamp.)â”‚ â”‚(Visualz)â”‚ â”‚(Notifs)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Infrastructure Setup

**InfluxDB Configuration:**

```toml
# influxdb.conf

[http]
  bind-address = ":8086"
  auth-enabled = true
  max-body-size = 25000000
  max-concurrent-queries = 10
  max-enqueued-writes = 100000

[data]
  cache-max-memory-size = 1073741824  # 1GB
  cache-snapshot-memory-size = 26214400
  cache-snapshot-write-cold-duration = "10m"
  compact-full-write-cold-duration = "4h"
  max-series-per-database = 1000000
  max-values-per-tag = 100000

[coordinator]
  write-timeout = "10s"
  max-concurrent-queries = 10
  query-timeout = "0s"
  log-queries-after = "15s"

[retention]
  enabled = true
  check-interval = "30m"
```

### Database Schema Design

**Bucket Strategy:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bucket             â”‚ Retention    â”‚ Precision   â”‚ Purpose      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ system_metrics_raw â”‚ 7 days       â”‚ 1 second    â”‚ High detail  â”‚
â”‚ system_metrics_1h  â”‚ 90 days      â”‚ 1 hour      â”‚ Analysis     â”‚
â”‚ system_metrics_1d  â”‚ 1 year       â”‚ 1 day       â”‚ Historical   â”‚
â”‚ alerts_history     â”‚ 30 days      â”‚ 1 second    â”‚ Alert logs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Measurement Schema:**

```
Measurement: system_metrics
Tags:
  - host: server_name
  - region: datacenter_location
  - environment: prod/staging/dev
  - service: application_name

Fields:
  - cpu_usage_percent: float
  - cpu_load_1m: float
  - cpu_load_5m: float
  - cpu_load_15m: float
  - memory_used_bytes: integer
  - memory_available_bytes: integer
  - memory_usage_percent: float
  - disk_used_bytes: integer
  - disk_available_bytes: integer
  - disk_usage_percent: float
  - network_bytes_sent: integer
  - network_bytes_recv: integer
  - network_packets_sent: integer
  - network_packets_recv: integer
```

---

## Phase 2: Data Collection

### Python Collection Agent

```python
#!/usr/bin/env python3
"""
Enterprise System Monitoring Agent
Collects and sends system metrics to InfluxDB
"""

import psutil
import platform
import time
from datetime import datetime
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS, WriteOptions
import logging
import os
import socket

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SystemMonitoringAgent:
    """Collects and sends system metrics to InfluxDB"""

    def __init__(self, config):
        self.config = config
        self.hostname = socket.gethostname()
        self.region = config.get('region', 'default')
        self.environment = config.get('environment', 'production')

        # Initialize InfluxDB client
        self.client = InfluxDBClient(
            url=config['influx_url'],
            token=config['influx_token'],
            org=config['influx_org']
        )

        # Configure write API with batching
        self.write_api = self.client.write_api(
            write_options=WriteOptions(
                batch_size=500,
                flush_interval=10_000,  # 10 seconds
                jitter_interval=2_000,
                retry_interval=5_000,
                max_retries=3,
                max_retry_delay=30_000,
                exponential_base=2
            )
        )

        logger.info(f"Monitoring agent initialized for host: {self.hostname}")

    def collect_cpu_metrics(self):
        """Collect CPU metrics"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()
            load_avg = psutil.getloadavg()
            cpu_freq = psutil.cpu_freq()

            point = Point("system_metrics") \
                .tag("host", self.hostname) \
                .tag("region", self.region) \
                .tag("environment", self.environment) \
                .tag("metric_type", "cpu") \
                .field("cpu_usage_percent", cpu_percent) \
                .field("cpu_count", cpu_count) \
                .field("cpu_load_1m", load_avg[0]) \
                .field("cpu_load_5m", load_avg[1]) \
                .field("cpu_load_15m", load_avg[2])

            if cpu_freq:
                point.field("cpu_freq_current_mhz", cpu_freq.current)

            return point
        except Exception as e:
            logger.error(f"Error collecting CPU metrics: {e}")
            return None

    def collect_memory_metrics(self):
        """Collect memory metrics"""
        try:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()

            point = Point("system_metrics") \
                .tag("host", self.hostname) \
                .tag("region", self.region) \
                .tag("environment", self.environment) \
                .tag("metric_type", "memory") \
                .field("memory_total_bytes", memory.total) \
                .field("memory_available_bytes", memory.available) \
                .field("memory_used_bytes", memory.used) \
                .field("memory_usage_percent", memory.percent) \
                .field("memory_cached_bytes", memory.cached) \
                .field("swap_total_bytes", swap.total) \
                .field("swap_used_bytes", swap.used) \
                .field("swap_usage_percent", swap.percent)

            return point
        except Exception as e:
            logger.error(f"Error collecting memory metrics: {e}")
            return None

    def collect_disk_metrics(self):
        """Collect disk metrics"""
        points = []
        try:
            for partition in psutil.disk_partitions():
                if partition.device.startswith('/dev/'):
                    try:
                        usage = psutil.disk_usage(partition.mountpoint)
                        io_counters = psutil.disk_io_counters(perdisk=False)

                        point = Point("system_metrics") \
                            .tag("host", self.hostname) \
                            .tag("region", self.region) \
                            .tag("environment", self.environment) \
                            .tag("metric_type", "disk") \
                            .tag("device", partition.device) \
                            .tag("mountpoint", partition.mountpoint) \
                            .field("disk_total_bytes", usage.total) \
                            .field("disk_used_bytes", usage.used) \
                            .field("disk_free_bytes", usage.free) \
                            .field("disk_usage_percent", usage.percent)

                        if io_counters:
                            point.field("disk_read_bytes", io_counters.read_bytes)
                            point.field("disk_write_bytes", io_counters.write_bytes)
                            point.field("disk_read_count", io_counters.read_count)
                            point.field("disk_write_count", io_counters.write_count)

                        points.append(point)
                    except PermissionError:
                        continue

            return points
        except Exception as e:
            logger.error(f"Error collecting disk metrics: {e}")
            return []

    def collect_network_metrics(self):
        """Collect network metrics"""
        try:
            net_io = psutil.net_io_counters()
            net_connections = len(psutil.net_connections())

            point = Point("system_metrics") \
                .tag("host", self.hostname) \
                .tag("region", self.region) \
                .tag("environment", self.environment) \
                .tag("metric_type", "network") \
                .field("network_bytes_sent", net_io.bytes_sent) \
                .field("network_bytes_recv", net_io.bytes_recv) \
                .field("network_packets_sent", net_io.packets_sent) \
                .field("network_packets_recv", net_io.packets_recv) \
                .field("network_errors_in", net_io.errin) \
                .field("network_errors_out", net_io.errout) \
                .field("network_drops_in", net_io.dropin) \
                .field("network_drops_out", net_io.dropout) \
                .field("network_connections", net_connections)

            return point
        except Exception as e:
            logger.error(f"Error collecting network metrics: {e}")
            return None

    def collect_process_metrics(self):
        """Collect process-level metrics"""
        try:
            process_count = len(psutil.pids())

            point = Point("system_metrics") \
                .tag("host", self.hostname) \
                .tag("region", self.region) \
                .tag("environment", self.environment) \
                .tag("metric_type", "process") \
                .field("process_count", process_count) \
                .field("uptime_seconds", time.time() - psutil.boot_time())

            return point
        except Exception as e:
            logger.error(f"Error collecting process metrics: {e}")
            return None

    def collect_all_metrics(self):
        """Collect all system metrics"""
        points = []

        # Collect CPU metrics
        cpu_point = self.collect_cpu_metrics()
        if cpu_point:
            points.append(cpu_point)

        # Collect memory metrics
        mem_point = self.collect_memory_metrics()
        if mem_point:
            points.append(mem_point)

        # Collect disk metrics
        disk_points = self.collect_disk_metrics()
        points.extend(disk_points)

        # Collect network metrics
        net_point = self.collect_network_metrics()
        if net_point:
            points.append(net_point)

        # Collect process metrics
        proc_point = self.collect_process_metrics()
        if proc_point:
            points.append(proc_point)

        return points

    def send_metrics(self, points):
        """Send metrics to InfluxDB"""
        try:
            self.write_api.write(
                bucket=self.config['influx_bucket'],
                record=points
            )
            logger.info(f"Successfully sent {len(points)} metric points")
            return True
        except Exception as e:
            logger.error(f"Error sending metrics: {e}")
            return False

    def run(self, interval=30):
        """Main monitoring loop"""
        logger.info(f"Starting monitoring loop (interval: {interval}s)")

        while True:
            try:
                # Collect metrics
                start_time = time.time()
                points = self.collect_all_metrics()

                # Send to InfluxDB
                if points:
                    self.send_metrics(points)

                # Calculate sleep time
                elapsed = time.time() - start_time
                sleep_time = max(0, interval - elapsed)

                logger.debug(f"Collection took {elapsed:.2f}s, sleeping {sleep_time:.2f}s")
                time.sleep(sleep_time)

            except KeyboardInterrupt:
                logger.info("Monitoring stopped by user")
                break
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(interval)

    def close(self):
        """Clean up resources"""
        try:
            self.write_api.close()
            self.client.close()
            logger.info("Monitoring agent closed")
        except Exception as e:
            logger.error(f"Error closing agent: {e}")

# Configuration
CONFIG = {
    'influx_url': os.getenv('INFLUX_URL', 'http://localhost:8086'),
    'influx_token': os.getenv('INFLUX_TOKEN', 'your-token-here'),
    'influx_org': os.getenv('INFLUX_ORG', 'myorg'),
    'influx_bucket': os.getenv('INFLUX_BUCKET', 'system_metrics_raw'),
    'region': os.getenv('REGION', 'us-east-1'),
    'environment': os.getenv('ENVIRONMENT', 'production')
}

if __name__ == "__main__":
    agent = SystemMonitoringAgent(CONFIG)
    try:
        agent.run(interval=30)
    finally:
        agent.close()
```

### Docker Compose for Multi-Server Simulation

```yaml
# docker-compose.yml
version: "3.8"

services:
  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=adminpassword
      - DOCKER_INFLUXDB_INIT_ORG=myorg
      - DOCKER_INFLUXDB_INIT_BUCKET=system_metrics_raw
      - DOCKER_INFLUXDB_INIT_RETENTION=7d
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=my-super-secret-token
    volumes:
      - influxdb-data:/var/lib/influxdb2
      - influxdb-config:/etc/influxdb2
    networks:
      - monitoring

  monitoring-agent-1:
    build: .
    container_name: agent-server-1
    environment:
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_TOKEN=my-super-secret-token
      - INFLUX_ORG=myorg
      - INFLUX_BUCKET=system_metrics_raw
      - REGION=us-east-1
      - ENVIRONMENT=production
    depends_on:
      - influxdb
    networks:
      - monitoring

  monitoring-agent-2:
    build: .
    container_name: agent-server-2
    environment:
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_TOKEN=my-super-secret-token
      - INFLUX_ORG=myorg
      - INFLUX_BUCKET=system_metrics_raw
      - REGION=us-west-1
      - ENVIRONMENT=production
    depends_on:
      - influxdb
    networks:
      - monitoring

  monitoring-agent-3:
    build: .
    container_name: agent-server-3
    environment:
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_TOKEN=my-super-secret-token
      - INFLUX_ORG=myorg
      - INFLUX_BUCKET=system_metrics_raw
      - REGION=eu-west-1
      - ENVIRONMENT=staging
    depends_on:
      - influxdb
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - influxdb
    networks:
      - monitoring

volumes:
  influxdb-data:
  influxdb-config:
  grafana-data:

networks:
  monitoring:
    driver: bridge
```

---

## Phase 3: Storage & Retention

### Bucket Configuration Script

```python
#!/usr/bin/env python3
"""
Setup buckets and retention policies
"""

from influxdb_client import InfluxDBClient
from influxdb_client.domain.retention_rule import RetentionRule

def setup_buckets(client, org):
    """Create buckets with appropriate retention policies"""
    buckets_api = client.buckets_api()

    # Define buckets
    bucket_configs = [
        {
            'name': 'system_metrics_raw',
            'retention': 7 * 24 * 3600,  # 7 days in seconds
            'description': 'Raw metrics with high precision (1s)'
        },
        {
            'name': 'system_metrics_1h',
            'retention': 90 * 24 * 3600,  # 90 days
            'description': 'Hourly aggregated metrics'
        },
        {
            'name': 'system_metrics_1d',
            'retention': 365 * 24 * 3600,  # 1 year
            'description': 'Daily aggregated metrics'
        },
        {
            'name': 'alerts_history',
            'retention': 30 * 24 * 3600,  # 30 days
            'description': 'Alert event history'
        }
    ]

    for config in bucket_configs:
        try:
            # Check if bucket exists
            existing = buckets_api.find_bucket_by_name(config['name'])

            if existing:
                print(f"Bucket '{config['name']}' already exists")
            else:
                # Create bucket
                retention_rules = RetentionRule(
                    type="expire",
                    every_seconds=config['retention']
                )

                bucket = buckets_api.create_bucket(
                    bucket_name=config['name'],
                    org=org,
                    retention_rules=retention_rules,
                    description=config['description']
                )

                print(f"Created bucket: {config['name']}")

        except Exception as e:
            print(f"Error creating bucket {config['name']}: {e}")

if __name__ == "__main__":
    client = InfluxDBClient(
        url="http://localhost:8086",
        token="my-super-secret-token",
        org="myorg"
    )

    setup_buckets(client, "myorg")
    client.close()
```

### Downsampling Tasks

```flux
// Task 1: Hourly Downsampling
option task = {
    name: "Hourly Downsampling",
    every: 1h,
    offset: 5m
}

from(bucket: "system_metrics_raw")
    |> range(start: -1h)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> aggregateWindow(
        every: 1h,
        fn: mean,
        createEmpty: false
    )
    |> set(key: "_measurement", value: "system_metrics_hourly")
    |> to(bucket: "system_metrics_1h", org: "myorg")

// Task 2: Daily Downsampling
option task = {
    name: "Daily Downsampling",
    every: 1d,
    offset: 1h
}

from(bucket: "system_metrics_1h")
    |> range(start: -1d)
    |> filter(fn: (r) => r._measurement == "system_metrics_hourly")
    |> aggregateWindow(
        every: 1d,
        fn: mean,
        createEmpty: false
    )
    |> set(key: "_measurement", value: "system_metrics_daily")
    |> to(bucket: "system_metrics_1d", org: "myorg")

// Task 3: Calculate and store statistics
option task = {
    name: "Calculate Statistics",
    every: 1h,
    offset: 10m
}

data = from(bucket: "system_metrics_raw")
    |> range(start: -1h)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r.metric_type == "cpu")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")

// Calculate min, max, mean, stddev
stats = data
    |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
    |> set(key: "_field", value: "cpu_usage_mean")

min_values = data
    |> aggregateWindow(every: 1h, fn: min, createEmpty: false)
    |> set(key: "_field", value: "cpu_usage_min")

max_values = data
    |> aggregateWindow(every: 1h, fn: max, createEmpty: false)
    |> set(key: "_field", value: "cpu_usage_max")

stddev_values = data
    |> aggregateWindow(every: 1h, fn: stddev, createEmpty: false)
    |> set(key: "_field", value: "cpu_usage_stddev")

// Combine and write
union(tables: [stats, min_values, max_values, stddev_values])
    |> to(bucket: "system_metrics_1h", org: "myorg")
```

---

## Phase 4: Querying & Analytics

### Essential Queries

#### 1. Current System Status

```flux
// Real-time status across all servers
from(bucket: "system_metrics_raw")
    |> range(start: -5m)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent" or
                         r._field == "memory_usage_percent" or
                         r._field == "disk_usage_percent")
    |> last()
    |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
    |> group(columns: ["host"])
```

#### 2. Historical Trends

```flux
// 24-hour CPU trend with hourly averages
from(bucket: "system_metrics_raw")
    |> range(start: -24h)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")
    |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
    |> yield(name: "hourly_cpu_average")
```

#### 3. Multi-Server Comparison

```flux
// Compare CPU usage across all servers
from(bucket: "system_metrics_raw")
    |> range(start: -1h)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")
    |> aggregateWindow(every: 5m, fn: mean)
    |> pivot(rowKey:["_time"], columnKey: ["host"], valueColumn: "_value")
```

#### 4. Anomaly Detection

```flux
// Detect CPU usage anomalies using statistical methods
import "experimental"

data = from(bucket: "system_metrics_raw")
    |> range(start: -7d)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")
    |> aggregateWindow(every: 5m, fn: mean)

// Calculate mean and standard deviation
stats = data
    |> duplicate(column: "_value", as: "value_copy")
    |> mean()
    |> set(key: "_field", value: "mean")

stddev_data = data
    |> stddev()
    |> set(key: "_field", value: "stddev")

// Join statistics with recent data
recent_data = from(bucket: "system_metrics_raw")
    |> range(start: -1h)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")

// Identify anomalies (values beyond 2 standard deviations)
join(
    tables: {data: recent_data, stats: stats},
    on: ["host"]
)
    |> map(fn: (r) => ({
        r with
        z_score: (r._value - r.mean) / r.stddev,
        is_anomaly: if (r._value - r.mean) / r.stddev > 2.0 or
                       (r._value - r.mean) / r.stddev < -2.0
                    then 1 else 0
    }))
    |> filter(fn: (r) => r.is_anomaly == 1)
```

#### 5. Resource Capacity Planning

```flux
// Predict when disk will be full based on trend
import "experimental"

from(bucket: "system_metrics_1h")
    |> range(start: -30d)
    |> filter(fn: (r) => r._measurement == "system_metrics_hourly")
    |> filter(fn: (r) => r._field == "disk_usage_percent")
    |> filter(fn: (r) => r.host == "server-1")
    |> holtWinters(
        n: 720,  // Forecast 30 days ahead (hourly)
        seasonality: 24,  // Daily pattern
        interval: 1h
    )
```

### Parameterized Query Functions

```flux
// Reusable query function
getServerMetrics = (server, metric, timeRange) =>
    from(bucket: "system_metrics_raw")
        |> range(start: timeRange)
        |> filter(fn: (r) => r._measurement == "system_metrics")
        |> filter(fn: (r) => r.host == server)
        |> filter(fn: (r) => r._field == metric)
        |> aggregateWindow(every: 1m, fn: mean)

// Usage
getServerMetrics(
    server: "server-1",
    metric: "cpu_usage_percent",
    timeRange: -1h
)
```

---

## Phase 5: Visualization

### Grafana Dashboard Configuration

```json
{
  "dashboard": {
    "title": "System Monitoring Dashboard",
    "tags": ["monitoring", "system"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "CPU Usage - All Servers",
        "type": "timeseries",
        "datasource": "InfluxDB",
        "targets": [
          {
            "query": "from(bucket: \"system_metrics_raw\")\n  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |> filter(fn: (r) => r._measurement == \"system_metrics\")\n  |> filter(fn: (r) => r._field == \"cpu_usage_percent\")\n  |> aggregateWindow(every: v.windowPeriod, fn: mean)"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "mode": "absolute",
              "steps": [
                { "value": 0, "color": "green" },
                { "value": 70, "color": "yellow" },
                { "value": 90, "color": "red" }
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Memory Usage",
        "type": "gauge",
        "datasource": "InfluxDB",
        "targets": [
          {
            "query": "from(bucket: \"system_metrics_raw\")\n  |> range(start: -5m)\n  |> filter(fn: (r) => r._measurement == \"system_metrics\")\n  |> filter(fn: (r) => r._field == \"memory_usage_percent\")\n  |> last()"
          }
        ]
      },
      {
        "id": 3,
        "title": "Disk Usage by Server",
        "type": "bar",
        "datasource": "InfluxDB",
        "targets": [
          {
            "query": "from(bucket: \"system_metrics_raw\")\n  |> range(start: -5m)\n  |> filter(fn: (r) => r._measurement == \"system_metrics\")\n  |> filter(fn: (r) => r._field == \"disk_usage_percent\")\n  |> last()\n  |> group(columns: [\"host\"])"
          }
        ]
      },
      {
        "id": 4,
        "title": "Network Traffic",
        "type": "timeseries",
        "datasource": "InfluxDB",
        "targets": [
          {
            "query": "from(bucket: \"system_metrics_raw\")\n  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |> filter(fn: (r) => r._measurement == \"system_metrics\")\n  |> filter(fn: (r) => r._field == \"network_bytes_sent\" or r._field == \"network_bytes_recv\")\n  |> derivative(unit: 1s, nonNegative: true)"
          }
        ]
      }
    ]
  }
}
```

### Custom HTML Dashboard

```html
<!DOCTYPE html>
<html>
  <head>
    <title>System Monitoring Dashboard</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@influxdata/influxdb-client-browser@latest/dist/index.browser.mjs"></script>
    <style>
      body {
        font-family: Arial;
        margin: 20px;
        background: #1a1a1a;
        color: white;
      }
      .dashboard {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
        gap: 20px;
      }
      .panel {
        background: #2a2a2a;
        padding: 20px;
        border-radius: 8px;
      }
      .metric {
        font-size: 2em;
        font-weight: bold;
      }
      .label {
        color: #999;
        font-size: 0.9em;
      }
    </style>
  </head>
  <body>
    <h1>System Monitoring Dashboard</h1>
    <div class="dashboard">
      <div class="panel" id="cpu-panel"></div>
      <div class="panel" id="memory-panel"></div>
      <div class="panel" id="disk-panel"></div>
      <div class="panel" id="network-panel"></div>
    </div>

    <script type="module">
      import { InfluxDB } from "https://cdn.jsdelivr.net/npm/@influxdata/influxdb-client-browser@latest/dist/index.browser.mjs";

      const influxDB = new InfluxDB({
        url: "http://localhost:8086",
        token: "my-super-secret-token",
      });

      const queryApi = influxDB.getQueryApi("myorg");

      async function updateCPUChart() {
        const query = `
                from(bucket: "system_metrics_raw")
                    |> range(start: -1h)
                    |> filter(fn: (r) => r._measurement == "system_metrics")
                    |> filter(fn: (r) => r._field == "cpu_usage_percent")
                    |> aggregateWindow(every: 1m, fn: mean)
            `;

        const data = await queryApi.collectRows(query);

        const traces = {};
        data.forEach((row) => {
          if (!traces[row.host]) {
            traces[row.host] = {
              x: [],
              y: [],
              name: row.host,
              type: "scatter",
            };
          }
          traces[row.host].x.push(new Date(row._time));
          traces[row.host].y.push(row._value);
        });

        Plotly.newPlot("cpu-panel", Object.values(traces), {
          title: "CPU Usage",
          yaxis: { title: "Percentage", range: [0, 100] },
          template: "plotly_dark",
        });
      }

      // Update every 30 seconds
      updateCPUChart();
      setInterval(updateCPUChart, 30000);
    </script>
  </body>
</html>
```

---

## Phase 6: Alerting

### Alert Check Configuration

```flux
// Alert Check: High CPU Usage
import "influxdata/influxdb/monitor"
import "slack"

option task = {
    name: "Alert: High CPU Usage",
    every: 1m
}

// Query recent data
data = from(bucket: "system_metrics_raw")
    |> range(start: -5m)
    |> filter(fn: (r) => r._measurement == "system_metrics")
    |> filter(fn: (r) => r._field == "cpu_usage_percent")
    |> mean()

// Check threshold
data
    |> monitor.check(
        crit: (r) => r._value >= 90.0,
        warn: (r) => r._value >= 70.0,
        messageFn: (r) => "CPU usage is ${r._level}: ${r._value}% on ${r.host}",
        data: {
            _check_name: "CPU Usage",
            _type: "threshold"
        }
    )
    |> monitor.write(bucket: "alerts_history")

// Send Slack notification for critical alerts
data
    |> filter(fn: (r) => r._value >= 90.0)
    |> slack.message(
        url: "https://hooks.slack.com/services/YOUR/WEBHOOK/URL",
        channel: "#alerts",
        text: "ðŸš¨ CRITICAL: CPU usage at ${r._value}% on ${r.host}",
        color: "danger"
    )
```

### Python Alert Manager

```python
#!/usr/bin/env python3
"""
Alert Management System
"""

from influxdb_client import InfluxDBClient
from datetime import datetime, timedelta
import requests
import json
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AlertManager:
    """Manage alerts and notifications"""

    def __init__(self, config):
        self.config = config
        self.client = InfluxDBClient(
            url=config['influx_url'],
            token=config['influx_token'],
            org=config['influx_org']
        )
        self.query_api = self.client.query_api()
        self.alert_state = {}  # Track alert states to prevent spam

    def check_cpu_threshold(self, threshold=90, duration_minutes=5):
        """Check if CPU usage exceeds threshold"""
        query = f'''
        from(bucket: "system_metrics_raw")
            |> range(start: -{duration_minutes}m)
            |> filter(fn: (r) => r._measurement == "system_metrics")
            |> filter(fn: (r) => r._field == "cpu_usage_percent")
            |> mean()
            |> filter(fn: (r) => r._value > {threshold})
        '''

        alerts = []
        result = self.query_api.query(query)

        for table in result:
            for record in table.records:
                alert = {
                    'type': 'cpu_high',
                    'severity': 'critical' if record.get_value() > 95 else 'warning',
                    'host': record.values.get('host'),
                    'metric': 'cpu_usage_percent',
                    'value': record.get_value(),
                    'threshold': threshold,
                    'timestamp': datetime.now().isoformat()
                }
                alerts.append(alert)

        return alerts

    def check_memory_threshold(self, threshold=85):
        """Check if memory usage exceeds threshold"""
        query = f'''
        from(bucket: "system_metrics_raw")
            |> range(start: -5m)
            |> filter(fn: (r) => r._measurement == "system_metrics")
            |> filter(fn: (r) => r._field == "memory_usage_percent")
            |> mean()
            |> filter(fn: (r) => r._value > {threshold})
        '''

        alerts = []
        result = self.query_api.query(query)

        for table in result:
            for record in table.records:
                alert = {
                    'type': 'memory_high',
                    'severity': 'critical' if record.get_value() > 95 else 'warning',
                    'host': record.values.get('host'),
                    'metric': 'memory_usage_percent',
                    'value': record.get_value(),
                    'threshold': threshold,
                    'timestamp': datetime.now().isoformat()
                }
                alerts.append(alert)

        return alerts

    def check_disk_threshold(self, threshold=80):
        """Check if disk usage exceeds threshold"""
        query = f'''
        from(bucket: "system_metrics_raw")
            |> range(start: -5m)
            |> filter(fn: (r) => r._measurement == "system_metrics")
            |> filter(fn: (r) => r._field == "disk_usage_percent")
            |> last()
            |> filter(fn: (r) => r._value > {threshold})
        '''

        alerts = []
        result = self.query_api.query(query)

        for table in result:
            for record in table.records:
                alert = {
                    'type': 'disk_high',
                    'severity': 'warning',
                    'host': record.values.get('host'),
                    'metric': 'disk_usage_percent',
                    'value': record.get_value(),
                    'threshold': threshold,
                    'timestamp': datetime.now().isoformat()
                }
                alerts.append(alert)

        return alerts

    def should_send_alert(self, alert):
        """Check if we should send alert (prevent spam)"""
        alert_key = f"{alert['type']}_{alert['host']}"

        if alert_key not in self.alert_state:
            self.alert_state[alert_key] = {
                'last_sent': None,
                'count': 0
            }

        state = self.alert_state[alert_key]
        now = datetime.now()

        # Send alert if:
        # 1. Never sent before
        # 2. Last alert was more than 30 minutes ago
        if state['last_sent'] is None or \
           (now - state['last_sent']).total_seconds() > 1800:
            state['last_sent'] = now
            state['count'] += 1
            return True

        return False

    def send_slack_notification(self, alert):
        """Send alert to Slack"""
        webhook_url = self.config.get('slack_webhook')
        if not webhook_url:
            return

        emoji = "ðŸš¨" if alert['severity'] == 'critical' else "âš ï¸"
        color = "danger" if alert['severity'] == 'critical' else "warning"

        message = {
            "attachments": [{
                "color": color,
                "title": f"{emoji} {alert['type'].upper()} Alert",
                "fields": [
                    {"title": "Host", "value": alert['host'], "short": True},
                    {"title": "Metric", "value": alert['metric'], "short": True},
                    {"title": "Value", "value": f"{alert['value']:.2f}%", "short": True},
                    {"title": "Threshold", "value": f"{alert['threshold']}%", "short": True},
                    {"title": "Severity", "value": alert['severity'].upper(), "short": True},
                    {"title": "Time", "value": alert['timestamp'], "short": True}
                ]
            }]
        }

        try:
            response = requests.post(webhook_url, json=message)
            response.raise_for_status()
            logger.info(f"Sent Slack notification for {alert['type']} on {alert['host']}")
        except Exception as e:
            logger.error(f"Failed to send Slack notification: {e}")

    def send_email_notification(self, alert):
        """Send alert via email"""
        # Implement email sending logic here
        pass

    def run_checks(self):
        """Run all alert checks"""
        all_alerts = []

        # Run checks
        all_alerts.extend(self.check_cpu_threshold())
        all_alerts.extend(self.check_memory_threshold())
        all_alerts.extend(self.check_disk_threshold())

        # Send notifications
        for alert in all_alerts:
            if self.should_send_alert(alert):
                logger.info(f"Triggering alert: {alert}")
                self.send_slack_notification(alert)

        return all_alerts

    def run(self, interval=60):
        """Main alert loop"""
        import time
        logger.info("Alert manager started")

        while True:
            try:
                alerts = self.run_checks()
                if alerts:
                    logger.info(f"Found {len(alerts)} active alerts")
                time.sleep(interval)
            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f"Error in alert loop: {e}")
                time.sleep(interval)

# Configuration
CONFIG = {
    'influx_url': 'http://localhost:8086',
    'influx_token': 'my-super-secret-token',
    'influx_org': 'myorg',
    'slack_webhook': 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
}

if __name__ == "__main__":
    manager = AlertManager(CONFIG)
    manager.run(interval=60)
```

---

## Performance Validation & Tuning

### Performance Testing Script

```python
#!/usr/bin/env python3
"""
Performance validation and benchmarking
"""

import time
import statistics
from influxdb_client import InfluxDBClient, Point
from concurrent.futures import ThreadPoolExecutor
import random

class PerformanceTester:
    """Test InfluxDB performance"""

    def __init__(self, url, token, org, bucket):
        self.client = InfluxDBClient(url=url, token=token, org=org)
        self.bucket = bucket
        self.results = {
            'write_latencies': [],
            'query_latencies': [],
            'errors': []
        }

    def test_write_performance(self, num_points=10000, batch_size=1000):
        """Test write performance"""
        print(f"\nTesting write performance: {num_points} points...")

        write_api = self.client.write_api()
        points = []

        start_time = time.time()

        for i in range(num_points):
            point = Point("benchmark") \
                .tag("test", "write_performance") \
                .tag("host", f"server_{i % 10}") \
                .field("value", random.uniform(0, 100))
            points.append(point)

            if len(points) >= batch_size:
                batch_start = time.time()
                try:
                    write_api.write(bucket=self.bucket, record=points)
                    batch_time = time.time() - batch_start
                    self.results['write_latencies'].append(batch_time)
                except Exception as e:
                    self.results['errors'].append(str(e))
                points = []

        # Write remaining points
        if points:
            write_api.write(bucket=self.bucket, record=points)

        total_time = time.time() - start_time
        throughput = num_points / total_time

        print(f"âœ“ Write test complete")
        print(f"  Total time: {total_time:.2f}s")
        print(f"  Throughput: {throughput:.2f} points/sec")
        print(f"  Avg batch latency: {statistics.mean(self.results['write_latencies']):.4f}s")

    def test_query_performance(self, num_queries=100):
        """Test query performance"""
        print(f"\nTesting query performance: {num_queries} queries...")

        query_api = self.client.query_api()

        queries = [
            'from(bucket: "{}") |> range(start: -1h) |> filter(fn: (r) => r._measurement == "benchmark") |> count()'.format(self.bucket),
            'from(bucket: "{}") |> range(start: -1h) |> filter(fn: (r) => r._measurement == "benchmark") |> mean()'.format(self.bucket),
            'from(bucket: "{}") |> range(start: -1h) |> filter(fn: (r) => r._measurement == "benchmark") |> aggregateWindow(every: 1m, fn: mean)'.format(self.bucket),
        ]

        for i in range(num_queries):
            query = queries[i % len(queries)]
            start_time = time.time()

            try:
                result = query_api.query(query)
                query_time = time.time() - start_time
                self.results['query_latencies'].append(query_time)
            except Exception as e:
                self.results['errors'].append(str(e))

        if self.results['query_latencies']:
            print(f"âœ“ Query test complete")
            print(f"  Avg latency: {statistics.mean(self.results['query_latencies']):.4f}s")
            print(f"  Min latency: {min(self.results['query_latencies']):.4f}s")
            print(f"  Max latency: {max(self.results['query_latencies']):.4f}s")
            print(f"  P95 latency: {statistics.quantiles(self.results['query_latencies'], n=20)[18]:.4f}s")

    def test_concurrent_writes(self, num_threads=10, points_per_thread=1000):
        """Test concurrent write performance"""
        print(f"\nTesting concurrent writes: {num_threads} threads...")

        def write_batch(thread_id):
            write_api = self.client.write_api()
            points = []

            for i in range(points_per_thread):
                point = Point("benchmark") \
                    .tag("thread", str(thread_id)) \
                    .tag("test", "concurrent") \
                    .field("value", random.uniform(0, 100))
                points.append(point)

            start_time = time.time()
            write_api.write(bucket=self.bucket, record=points)
            return time.time() - start_time

        start_time = time.time()

        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(write_batch, i) for i in range(num_threads)]
            latencies = [f.result() for f in futures]

        total_time = time.time() - start_time
        total_points = num_threads * points_per_thread
        throughput = total_points / total_time

        print(f"âœ“ Concurrent write test complete")
        print(f"  Total time: {total_time:.2f}s")
        print(f"  Throughput: {throughput:.2f} points/sec")
        print(f"  Avg thread time: {statistics.mean(latencies):.2f}s")

    def print_summary(self):
        """Print test summary"""
        print("\n" + "="*60)
        print("PERFORMANCE TEST SUMMARY")
        print("="*60)

        if self.results['write_latencies']:
            print(f"\nWrite Performance:")
            print(f"  Batches: {len(self.results['write_latencies'])}")
            print(f"  Avg latency: {statistics.mean(self.results['write_latencies']):.4f}s")

        if self.results['query_latencies']:
            print(f"\nQuery Performance:")
            print(f"  Queries: {len(self.results['query_latencies'])}")
            print(f"  Avg latency: {statistics.mean(self.results['query_latencies']):.4f}s")
            print(f"  P95 latency: {statistics.quantiles(self.results['query_latencies'], n=20)[18]:.4f}s")

        if self.results['errors']:
            print(f"\nErrors: {len(self.results['errors'])}")
            for error in self.results['errors'][:5]:
                print(f"  - {error}")

if __name__ == "__main__":
    tester = PerformanceTester(
        url="http://localhost:8086",
        token="my-super-secret-token",
        org="myorg",
        bucket="system_metrics_raw"
    )

    tester.test_write_performance(num_points=10000, batch_size=1000)
    tester.test_query_performance(num_queries=100)
    tester.test_concurrent_writes(num_threads=10, points_per_thread=1000)
    tester.print_summary()
```

### Performance Tuning Checklist

**1. Write Optimization**

- âœ… Use batch writes (500-5000 points per batch)
- âœ… Enable compression
- âœ… Use appropriate precision (reduce if possible)
- âœ… Optimize tag cardinality (< 100K unique combinations)
- âœ… Configure write buffer size appropriately

**2. Query Optimization**

- âœ… Use specific time ranges
- âœ… Filter early in the pipeline
- âœ… Use appropriate aggregation windows
- âœ… Limit result sets
- âœ… Leverage downsampled data for historical queries

**3. Storage Optimization**

- âœ… Implement retention policies
- âœ… Use downsampling for long-term storage
- âœ… Monitor shard sizes
- âœ… Configure TSM compaction settings
- âœ… Use appropriate compression

**4. Resource Allocation**

- âœ… Allocate sufficient RAM (4-8GB minimum)
- âœ… Use SSDs for storage
- âœ… Configure cache appropriately
- âœ… Monitor CPU usage
- âœ… Configure connection limits

---

## Production Best Practices

### 1. Security

```yaml
# Security checklist
âœ… Enable authentication
âœ… Use HTTPS/TLS
âœ… Implement token rotation
âœ… Use least-privilege tokens
âœ… Enable audit logging
âœ… Implement network isolation
âœ… Regular security updates
âœ… Backup encryption
âœ… Secrets management
```

### 2. High Availability

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Load Balancer (HAProxy)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
    â”‚InfluxDBâ”‚   â”‚InfluxDBâ”‚
    â”‚Primary â”‚   â”‚Replica â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  Shared Storage/NFS   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Monitoring InfluxDB Itself

```flux
// Monitor InfluxDB internal metrics
from(bucket: "_monitoring")
    |> range(start: -1h)
    |> filter(fn: (r) => r._measurement == "influxdb_httpd")
    |> filter(fn: (r) => r._field == "req_duration_ms")
    |> aggregateWindow(every: 1m, fn: mean)
```

### 4. Backup Strategy

```bash
#!/bin/bash
# Backup script

BACKUP_DIR="/backups/influxdb"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_PATH="$BACKUP_DIR/backup_$DATE"

# Create backup
influx backup "$BACKUP_PATH" \
  --host http://localhost:8086 \
  --token "$INFLUX_TOKEN"

# Compress backup
tar -czf "$BACKUP_PATH.tar.gz" "$BACKUP_PATH"
rm -rf "$BACKUP_PATH"

# Upload to S3 (optional)
aws s3 cp "$BACKUP_PATH.tar.gz" s3://my-bucket/influxdb-backups/

# Keep only last 30 days
find "$BACKUP_DIR" -name "backup_*.tar.gz" -mtime +30 -delete

echo "Backup completed: $BACKUP_PATH.tar.gz"
```

### 5. Disaster Recovery

```yaml
Recovery Plan: 1. Verify backup integrity
  2. Provision new InfluxDB instance
  3. Restore from backup
  4. Verify data completeness
  5. Update DNS/load balancer
  6. Resume normal operations

RTO (Recovery Time Objective): 4 hours
RPO (Recovery Point Objective): 1 hour
```

### 6. Operational Runbook

```markdown
# InfluxDB Operations Runbook

## Daily Checks

- [ ] Verify all monitoring agents are running
- [ ] Check disk space (alert if > 80%)
- [ ] Review error logs
- [ ] Verify backup completion

## Weekly Checks

- [ ] Review performance metrics
- [ ] Check compaction status
- [ ] Review and optimize slow queries
- [ ] Update documentation

## Monthly Checks

- [ ] Test disaster recovery procedure
- [ ] Review and update capacity planning
- [ ] Security audit
- [ ] Update dependencies

## Incident Response

1. Identify impact and severity
2. Check system logs
3. Review monitoring dashboards
4. Implement fix or failover
5. Post-incident review
```

---

## Future Roadmap

### InfluxDB 3.x Overview

**Key Features:**

- **Apache Arrow & Parquet** - Modern columnar format
- **Object Storage Native** - Built for S3/cloud storage
- **SQL Support** - Full SQL query support alongside Flux
- **Better Performance** - 5-10x query performance improvement
- **Lower Costs** - Optimized for cloud economics

### Architecture Evolution

```
InfluxDB 2.x              â†’         InfluxDB 3.x
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TSM Files  â”‚                   â”‚Apache Parquetâ”‚
â”‚  (Proprietary)                   â”‚  (Standard)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local Storageâ”‚                   â”‚Object Storageâ”‚
â”‚              â”‚                   â”‚  (S3, GCS)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flux Only   â”‚                   â”‚  SQL + Flux  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Migration Path

```
Phase 1: Assessment
- Review current usage patterns
- Identify Flux vs SQL workloads
- Plan data migration strategy

Phase 2: Pilot
- Set up InfluxDB 3.x test environment
- Migrate subset of data
- Test queries and applications
- Validate performance

Phase 3: Migration
- Parallel running of both systems
- Gradual traffic migration
- Continuous monitoring
- Rollback plan ready

Phase 4: Optimization
- Optimize for new architecture
- Leverage SQL capabilities
- Optimize storage costs
```

### New Capabilities

**1. SQL Query Support**

```sql
-- Native SQL queries in InfluxDB 3.x
SELECT
    host,
    AVG(cpu_usage_percent) as avg_cpu,
    MAX(memory_usage_percent) as max_memory
FROM system_metrics
WHERE time >= NOW() - INTERVAL '1 hour'
GROUP BY host
ORDER BY avg_cpu DESC;
```

**2. Better Integration**

- Direct Pandas DataFrame support
- Arrow Flight for fast data transfer
- S3 Select for efficient querying
- Better BI tool integration

**3. Cost Optimization**

```
Traditional Setup:        InfluxDB 3.x:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SSDs      â”‚          â”‚Object Storageâ”‚
â”‚ $0.10/GB/mo â”‚          â”‚ $0.02/GB/mo  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   5x more expensive       80% cost reduction
```

### Ecosystem Evolution

**Growing Ecosystem:**

- Enhanced Telegraf plugins
- Better Grafana integration
- ML/AI integrations
- Real-time analytics platforms
- Edge computing solutions

---

## Final Assessment

### Knowledge Check

**1. Architecture Design (20 points)**

- Design a multi-tier retention strategy
- Explain tag vs field selection
- Describe downsampling approach

**2. Implementation (30 points)**

- Write a data collection agent
- Create retention policies
- Implement alerting logic

**3. Querying (20 points)**

- Write complex Flux queries
- Optimize slow queries
- Implement aggregations

**4. Operations (20 points)**

- Performance tuning
- Backup strategy
- Disaster recovery plan

**5. Best Practices (10 points)**

- Security considerations
- Scalability planning
- Documentation

### Capstone Project Rubric

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Component              â”‚ Points â”‚ Criteria â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Collection        â”‚   20   â”‚ Working, â”‚
â”‚                        â”‚        â”‚ efficientâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Storage & Retention    â”‚   15   â”‚ Multi-   â”‚
â”‚                        â”‚        â”‚ tier     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Querying               â”‚   15   â”‚ Optimizedâ”‚
â”‚                        â”‚        â”‚ queries  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Visualization          â”‚   15   â”‚ Real-timeâ”‚
â”‚                        â”‚        â”‚ dashboardâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Alerting               â”‚   15   â”‚ Accurate â”‚
â”‚                        â”‚        â”‚ triggers â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Performance            â”‚   10   â”‚ Meets    â”‚
â”‚                        â”‚        â”‚ targets  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Documentation          â”‚   10   â”‚ Complete â”‚
â”‚                        â”‚        â”‚ & clear  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total: 100 points
```

---

## Conclusion

Congratulations on completing the InfluxDB training course! You now have:

âœ… Deep understanding of time-series data concepts  
âœ… Hands-on experience with InfluxDB 2.x  
âœ… Production-ready implementation skills  
âœ… Performance optimization expertise  
âœ… Knowledge of best practices  
âœ… Awareness of future developments

### Next Steps

1. **Practice:** Build more projects
2. **Community:** Join InfluxDB forums
3. **Advanced Topics:** Explore InfluxDB 3.x
4. **Certifications:** Consider official certification
5. **Contribute:** Share knowledge with others

### Resources

- **Documentation:** https://docs.influxdata.com
- **Community:** https://community.influxdata.com
- **GitHub:** https://github.com/influxdata
- **Training:** https://university.influxdata.com
- **Blog:** https://www.influxdata.com/blog

---

**Thank you for participating in this training!**

**Course Complete** ðŸŽ‰
